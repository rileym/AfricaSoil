{
 "metadata": {
  "name": "",
  "signature": "sha256:976192a2a3c4eab584e9d18b08b46f6797bc78293afa2f2543fbac52c768c4d3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import sklearn.grid_search as grid_search\n",
      "import sklearn.cross_validation as cv\n",
      "import sklearn.preprocessing as pp\n",
      "import sklearn.metrics as metrics\n",
      "import soilCleanTools as clean\n",
      "import time\n",
      "import timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "*Everything below is now in soilTuneTools.py*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _evaluate(gs_obj, X, Y, p, scaler_dict, model_name, output_base_path):\n",
      "    '''\n",
      "    '''\n",
      "\n",
      "    # Build DataFrame to record results\n",
      "    \n",
      "    results_columns = pd.Index(targets.columns, name='Target')\n",
      "    results_index = pd.Index(list(scaler_dict), name='Feature Scaling')\n",
      "    results = pd.DataFrame(index = results_index, columns=results_columns) \n",
      "    \n",
      "    # Seperate out validation set.\n",
      "    \n",
      "    (train_idx, val_idx) = cv.train_test_split(wave.index, train_size = p)\n",
      "    \n",
      "    print('Beginning Evaluation...')\n",
      "    start_time = timeit.default_timer()\n",
      "    \n",
      "    for (scaler_name, scaler) in scaler_dict.iteritems():\n",
      "        \n",
      "        X_scld = scaler.fit_transform(X.loc[train_idx,:])\n",
      "        X_val_scld = scaler.transform(X.loc[val_idx,:])\n",
      "\n",
      "        # Fit model to the data (and perform CV to choose optimal meta-parameters) \n",
      "        for (target_name, y) in Y.iteritems() :\n",
      "\n",
      "            gs_obj.fit(X = X_scld, y = y.loc[train_idx])\n",
      "            y_pred = gs_obj.predict(X = X_val_scld)\n",
      "            mse = metrics.mean_squared_error(y_pred=y_pred, y_true=y.loc[val_idx]) #generalize\n",
      "            results.loc[scaler_name ,target_name] = np.sqrt(mse)\n",
      "\n",
      "            print_params(target_name, gs_obj.best_params_)\n",
      "\n",
      "    # Capture elapsed time\n",
      "    elapsed = timeit.default_timer() - start_time\n",
      "    print('Time elapsed in main loop: ' + str(elapsed))\n",
      "    nperms = len(scaler_dict)*len(grid_search.ParameterGrid(gs_obj.param_grid))\n",
      "    print('On ' + str(nperms) + ' parameter/scaling permutations.')\n",
      "    \n",
      "    # Write to disk.\n",
      "    path = output_base_path+model_name+'-results-'+time.strftime(\"%m-%d\")+'.csv'\n",
      "    results.to_csv(path = path)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _predict(gs_obj, X, Y, X_test, scaler_dict, model_name, output_base_path):\n",
      "    '''\n",
      "    '''\n",
      "\n",
      "    #Build DataFrame to record results\n",
      "\n",
      "    results_cols = pd.MultiIndex.from_product((list(scaler_dict), targets.columns), name=('Scaling','Target'))\n",
      "    results = pd.DataFrame(index=X_test.index, columns=results_cols)\n",
      "    \n",
      "    X_scld = scaler.fit_transform(X)\n",
      "    X_test_scld = scaler.transform(X_test)\n",
      "    \n",
      "    print('\\nBeginning Prediction...')\n",
      "    start_time = timeit.default_timer()\n",
      "    for (scaler_name, scaler) in scaler_dict.iteritems():\n",
      "        \n",
      "        # Fit model to the data \n",
      "        for (target_name, y) in Y.iteritems() :\n",
      "\n",
      "            gs_obj.fit(X = X_scld, y = y)\n",
      "            y_pred = gs_obj.predict(X = X_test_scld)\n",
      "            results[(scaler_name, target_name)] = y_pred\n",
      "\n",
      "            print_params(target_name, gs_obj.best_params_)\n",
      "\n",
      "\n",
      "    # Capture elapsed time\n",
      "\n",
      "    elapsed = timeit.default_timer() - start_time\n",
      "    print('Time elapsed in main loop: ' + str(elapsed))\n",
      "    nperms = len(scaler_dict)*len(grid_search.ParameterGrid(gs_obj.param_grid))\n",
      "    print('On ' + str(nperms) + ' parameter/scaling permutations.')\n",
      "\n",
      "    # Write to disk.\n",
      "\n",
      "    path = output_base_path+model_name+'-preds-'+time.strftime(\"%m-%d\")+'.csv' #model-preprocess-date\n",
      "    results.to_csv(path_or_buf = path)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def soilTune(gs_obj, X, Y, X_test = None,  \\\n",
      "            tasks = ['evaluate'], p = .9, scaler_dict = None, \\\n",
      "            model_name = None, output_base_path = './'):         #score = 'rmse')\n",
      "    '''\n",
      "    '''\n",
      "    \n",
      "    if scaler_dict is None:\n",
      "        scaler_dict = {'Identity' : pp.StandardScaler(with_mean = False, with_std = False)} \n",
      "    \n",
      "    if 'evaluate' in tasks:\n",
      "        \n",
      "        _evaluate(gs_obj, X, Y, p, scaler_dict, model_name, output_base_path)\n",
      "        \n",
      "    if ('predict' in tasks) & (X_test is not None):\n",
      "        \n",
      "        _predict(gs_obj, X, Y, X_test, scaler_dict, model_name, output_base_path)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}